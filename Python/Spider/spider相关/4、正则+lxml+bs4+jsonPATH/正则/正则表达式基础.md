### 不记文档，白忙一场

------

#### 正则概述

> ```python
> 几种常见正则的区别：http://www.cnblogs.com/chengmo/archive/2010/10/10/1847287.html
> 正则测试网站：http://tool.oschina.net/regex/
> ```

#### 正则常用方法

> ```python
> #注意：match()和search()的区别：match是第一个没有回返None，search是跳过接着找
> 	'''
> 	    str = 'abcdefwwa,3452362  adfaswerz2esadf'
>         p = re.compile(r'\d+')
>         #使用match
>         m = p.match(str)
>         print(m)  #返回None，自然不能用m.group()，否则报错
>         print('-------------------')
>         #2、查找
>         p = re.compile(r'\d+')
>         result = p.search(str)
>         print(result)
>         print(result.group())  #返回 3452362
> 	'''
> #注意：
> 	m.group() #取出匹配到的字符串
> 	m.span()  #范围
> 	m.start() #起始索引
> 	m.end() #结束索引
> #注意：
> 	match和search都是匹配一个
> 	findall是匹配所有
> # 正则的基本模块
> import re
> # 1. match 匹配
> str = 'abc243lljlf,jklo0459'
> # 编译正则表达式
> pattern = re.compile(r'\w+')
> # 从头开始匹配，只返回一个结果。可以指定查找范围。
> m = pattern.match(str)
> # m 是一个包含匹配结果的对象。没有匹配成功返回None
> print(m)
> # 如果想取出匹配到的字符串，使用m.group
> print(m.group())
> 
> # 2. search ,查找，从左往右查找，直到查到一个数据为止。并不会查询所有。
> pattern = re.compile(r'\d+')
> s = pattern.search(str)
> print(s)
> # search匹配到之后也是用group取出匹配到的字符串。
> # match()和search()的区别：match是第一个字符没有返回None，search是跳过接着找
> print(s.group())
> 
> 
> # 3. findall  返回所有匹配的结果，结果是一个list
> f = pattern.findall(str)
> print(f)
> 
> # 4. finditer 返回一个可迭代的对象。
> ft =  pattern.finditer(str)
> for item in ft:
>     print('起始%s, 结束%s, 范围%s, 数据%s' % (item.start(), item.end(), item.span(), item.group()))
> 
> 
> # 5.split分割字符串，返回列表
> str = 'aa,, hi   : : 74 , world'
> # 以正则中的字符来分割字符串。
> p = re.compile(r'[\,\s\:]+')
> sub_list = p.split(str)
> print(sub_list)  #['aa', 'hi', '74', 'world']
> 
> 
> # 6. sub替换
> #注意：匹配包括下划线的任何单词字符（等价于[A-Za-z0-9_]）
> str = '123 Hello, 456 World'
> #注意：匹配的模板是多个非单词字符 空格 多个非单词字符，出来的是123 Hello和456 World，但是()的作用是，只提取空号中的内容，所以应该是('123,'Hello')和('456','World')
> p = re.compile(r'(\w+) (\w+)')
> print(p.findall(str)) #[('123', 'Hello'), ('456', 'World')]
> # 执行替换 \1 代表str中匹配到的第一个（\w+） \2表示匹配到的第二个（\w+）
> print(p.sub(r'\2\1', str))  #[('123', 'Hello'), ('456', 'World')]
> print(p.sub(r'\2 zhangsan', str))  #Hello zhangsan, World zhangsan
> # sub高级用法， sub第一个参数可以是一个函数。
> # item表示匹配结果对象item.group(1)和上面的\1是一个样的
> def fun(item):
>     return 'cool' + item.group(2)
> print(p.sub(fun, str)) #coolHello, coolWorld
> 
> 
> #  7. 匹配汉字
> # 汉字在unicode编码中有一个特定的区域，开始为\u4e00,结束为\u9fa5如果一个字符串的unicode编码在这个区间内，说明就是汉字。
> str = '你好...xxxefjeio930345!@#O$我好。。。execue me 大家好fe'
> p = re.compile(u'[\u4e00-\u9fa5]+')
> print(p.findall(str))  #['你好', '我好', '大家好']
> 
> # 8. 贪婪模式和非贪婪模式
> str = 'aa<div>test1</div>bb<div>test2</div>cc'
> # 非贪婪模式，匹配到一个就不匹配了。
> p = re.compile(r'<div>(.*?)</div>')
> 
> m = p.search(str)
> print(m)  #<re.Match object; span=(2, 18), match='<div>test1</div>'>
> m = p.findall(str)
> print(m)  #['test1', 'test2']
> # 问号去掉就变成贪婪模式，尽量多的匹配。
> p = re.compile(r'<div>(.*)</div>')
> 
> m = p.search(str)
> print(m)  #<re.Match object; span=(2, 36), match='<div>test1</div>bb<div>test2</div>'>   
> m = p.findall(str)
> print(m) #['test1</div>bb<div>test2']
> ```

#### 正则匹配糗百图片src

> ```python
> import urllib.request
> import re
> import os
> 
> def download_image(image_url):
> 	dirpath = './qiubai'
> 	# 获取文件名
> 	filename = os.path.basename(image_url)
> 	# 拼接文件全路径
> 	filepath = os.path.join(dirpath, filename)
> 	# 下载图片
> 	urllib.request.urlretrieve(image_url, filepath)
> 	print(filepath + '下载完毕')
> 
> def handle_content(request):
> 	# 拿到页面
> 	response = urllib.request.urlopen(request)
> 	html = response.read().decode('utf-8')
> 	# 处理html，通过正则表达式拿到所有的图片链接，并且将图片下载到本地,加上re.S表示.可以匹配换行。
>     # 注意：在正则里面 “（）” 代表的是分组的意思，一个括号代表一个分组，你只能匹配到"()"中的内容
> 	pattern = re.compile(r'<div class="thumb">.*?<img src=(.*?) alt=.*?>.*?</div>', re.S)
> 	# 获取所有的图片的链接
> 	src_list = pattern.findall(html)
> 	# 遍历这个列表
> 	for src in src_list:
> 		# 取出两边的双引号
> 		src = src.strip('"')
> 		# 拼接完整的图片url
> 		image_url = 'https:' + src
> 		# 下载这个图片即可
> 		download_image(image_url)
> 
> 
> # 构建请求对象并且返回
> def handle_url(url, page):
> 	url = url + str(page)
> 	headers = {
> 		'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.108 Safari/537.36'
> 	}
> 	request = urllib.request.Request(url=url, headers=headers)
> 	return request
> 
> def main():
> 	url = 'https://www.qiushibaike.com/pic/page/'
> 	start_page = int(input('请输入抓取的起始页码:'))
> 	end_page = int(input('请输入抓取的结束页码:'))
> 	print('开始下载...........')
> 	for page in range(start_page, end_page + 1):
> 		# 拼接url，生成一个request
> 		request = handle_url(url, page)
> 		# 获取内容，处理内容
> 		handle_content(request)
> 	print('全部下载完毕')
> 
> 
> if __name__ == '__main__':
> 	main()
> ```