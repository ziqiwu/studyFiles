### 不记文档，白忙一场

------

#### 都有哪些语言可以实现爬虫

> ```python
> php：号称是世界最优美的语言，但是他不是很擅长这个，对多进程多线程支持的不好
> java：做起来也非常的不错，是python爬虫最主要的对手，代码太臃肿，代码量很大，重构成本非常的大，而我们		爬虫需要根据需求经常修改，所以它不好。
> c、c++：学习成本比较高，性能和效率非常高，没这么做的，仅仅是一个能力的体现。
> python：好，语法优美、代码简单，学习成本低，支持的模块多，有一个非常强大的爬虫框架，scrapy
> ```

#### 通用爬虫和聚焦爬虫概念

> ```python
> 通用爬虫：百度，360，谷歌，搜狗、、、必应   搜索引擎
> 			搜索引擎使用的爬虫就是通用爬虫
> 			（1）抓取网页
> 			（2）抓取数据
> 			（3）数据存储
> 			（4）数据处理
> 			（5）给你提供了检索服务
> 			抓取流程：
> 			（1）给一些起始的url，放入待爬取url队列
> 			（2）从队列中取出url，开始爬取
> 			（3）分析内容，获取网页中所有的url，继续执行第二步，直到结束
> 			搜索引擎如何获取一个新的网站的链接
> 			（1）主动给搜索引擎提交url
> 			（2）在其它网站中设置友情链接
> 			（3）百度和DNS服务商进行合作，加速收录新网站
> 聚焦爬虫
> 		根据自己的需求，去写一个网络爬虫程序，抓取对应的数据即可
> ```

#### robots协议

> ```python
> 淘宝就不让百度抓取 https://www.taobao.com/robots.txt
> 可以限制通用爬虫的抓取，哪些可以抓，哪些不能抓
> 仅仅是一个协议，一般情况只有大型搜索引擎遵从这个协议，你自己写的小爬虫，就算了，你可以随便抓取
> ```

#### 网站排名

> ```python
> 网站排名（SEO （Search Engine Optimization））即搜索引擎优化
> （1）根据pagerank值排名，根据流量、点击率等等进行综合的计算进行排名，值越高，排名越靠前
> （2）百度竞价排名，谁给的钱多，谁在最前面 
> ```

#### 爬虫的整体内容

> ```python
> 1、python语法
> 2、如何抓取页面，使用到python库
> 	urllib.reqeust  urllib.parse  requests
> 3、解析内容
> 	正则表达式、xpath、bs4、jsonpath
> 4、采集动态html
> 	selenium+phantomjs
> 5、scrapy
> 	高性能异步网络框架
> 6、分布式，scrapy-redis组件
> 	在scrapy的基础上增了一套组件，结合redis进行存储等功能
> 7、爬虫-反爬虫-反反爬虫之间的博弈过程
> 	其实爬虫到最后，让你头疼的不是复杂的界面，不是数据的提取，而是和对面相互博弈的过程
> 	反爬虫的一般手段：User-Agent、代理、验证码、动态数据加载、数据加密
> 	最终肯定能获取数据，公司值不值得，因为只要浏览器能够正常访问，那么数据就能拿到
> ```

